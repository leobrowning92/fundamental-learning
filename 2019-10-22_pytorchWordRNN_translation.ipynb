{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-10-22_fundamentallearning_pytorchWordRNN_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- follow this tutorial https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "- use reloading on training loop https://github.com/julvo/reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import unicodedata\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import pdb\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pytorch_tutorial.word_utils as word_utils\n",
    "from pytorch_tutorial.word_utils import (\n",
    "    prepare_data, \n",
    "    pair2tensors, \n",
    "    sentence2tensor,\n",
    "    timedelta_string,\n",
    "    SOS_token, \n",
    "    EOS_token, \n",
    "    MAX_LENGTH, \n",
    "    \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is : cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device is : {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get french english translations from https://www.manythings.org/anki/fra-eng.zip and put them in a folder `pytorch_tutorial/data/fra-eng/fra.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter for short sentences that start with 'i am', 'he is' etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "example loaded pair  ['va !', 'go .']\n",
      "total sentance pairs in data : 175623\n",
      "filtering data\n",
      "Filtered sentence pairs in data : 13019\n",
      "fra : 4790\n",
      "eng : 3083\n"
     ]
    }
   ],
   "source": [
    "fra_lang, eng_lang, sentence_pairs = prepare_data('fra', 'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['j ai ans .', 'i m .']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, inout_dim, hidden_dim=256):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(inout_dim, hidden_dim)\n",
    "        self.encoder = nn.GRU(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        embedding = self.embedding(x).view(1,1,-1)\n",
    "        output, hidden = self.encoder(embedding,hidden)\n",
    "        return output,hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_dim, device=DEVICE)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, inout_dim, hidden_dim=256):\n",
    "        super(DecoderRNN,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(inout_dim, hidden_dim)\n",
    "        self.encoder = nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, inout_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim =1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embedding = self.embedding(x).view(1,1,-1)\n",
    "        output, hidden = self.encoder(embedding, hidden)\n",
    "        output = self.softmax(self.hidden2out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_dim, device=DEVICE)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['j ai ans .', 'i m .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy pass into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_infer(dset):\n",
    "    dummy_pair = random.choice(dset)\n",
    "    dummy_in = sentence2tensor(fra_lang, dummy_pair[0], DEVICE)\n",
    "    dummy_out = sentence2tensor(eng_lang, dummy_pair[1], DEVICE)\n",
    "    enc_h0 = enc.init_hidden()\n",
    "    h = enc_h0\n",
    "\n",
    "    for i in range(dummy_in.size(0)):\n",
    "        _, h = enc(dummy_in[i],h)\n",
    "    enc_h = h\n",
    "\n",
    "    outs = []\n",
    "    hidden = enc_h\n",
    "    output = torch.tensor([[SOS_token]], device=DEVICE)\n",
    "    for i in range(dummy_out.size(0)):\n",
    "        output, h = dec(output,hidden)\n",
    "\n",
    "        top_value, top_index = output.topk(1)  \n",
    "        output = top_index.squeeze().detach()\n",
    "        outs.append(output)\n",
    "\n",
    "\n",
    "    [eng_lang.index2word[o.item()] for o in outs]\n",
    "    print(f\"x : {dummy_pair[0]}\")\n",
    "    print(f\"y : {dummy_pair[1]}\")\n",
    "    print(f\"ŷ : {' '.join([eng_lang.index2word[o.item()] for o in outs])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : ce n est pas mon cousin .\n",
      "y : he isn t my cousin .\n",
      "ŷ : exactly agree freaking spoiling guilty remodeling launch\n"
     ]
    }
   ],
   "source": [
    "random_infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_example(input_tensor, target_tensor, enc, dec, optimizer, criterion, teacher_forcing=0.5):\n",
    "    encoder_hidden = enc.init_hidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    target_length = input_tensor.size(0)\n",
    "    \n",
    "    for ei in range(target_length):\n",
    "        _, encoder_hidden = enc(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]],device=DEVICE)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for di in range(target_tensor.size(0)):\n",
    "        decoder_input, decoder_hidden = dec(decoder_input, decoder_hidden)\n",
    "        # for nll output = [batchsize, number of classes (words)] and target = correct class\n",
    "        loss += criterion(decoder_input,target_tensor[di])\n",
    "        if random.random()<teacher_forcing:\n",
    "            decoder_input = target_tensor[di] #teacher forcing\n",
    "        else:\n",
    "            topv, topi = decoder_input.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "    return loss\n",
    "\n",
    "def train_step(input_tensor, target_tensor, enc, dec, optimizer, criterion):\n",
    "    loss = eval_example(input_tensor, target_tensor, enc, dec, optimizer, criterion, teacher_forcing=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()/ target_tensor.size(0)\n",
    "\n",
    "def test_evaluate(test_set):\n",
    "    \n",
    "    for i, pair in enumerate(test_set):\n",
    "        input_tensor = pair[0]\n",
    "        target_tensor = pair[1]\n",
    "        loss_total = 0\n",
    "        with torch.no_grad():\n",
    "            loss = eval_example(input_tensor, target_tensor, enc, dec, optimizer, criterion)\n",
    "            loss_total += loss.item()/ target_tensor.size(0)\n",
    "        return loss_total\n",
    "\n",
    "def train(training_set, test_set, epochs, print_every):\n",
    "    set_size = len(training_set)\n",
    "    start_time = datetime.now()\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for e in range(epochs):\n",
    "        for i, pair in enumerate(training_set):\n",
    "            n_example = ((e)*set_size + (i+1))\n",
    "            input_tensor = pair[0]\n",
    "            target_tensor = pair[1]\n",
    "            loss_total =0\n",
    "            loss = train_step(input_tensor, target_tensor, enc, dec, optimizer, criterion)\n",
    "            train_losses.append((n_example,loss))\n",
    "            loss_total += loss\n",
    "\n",
    "            if ((e)*set_size + (i+1))%print_every ==0:\n",
    "                timestamp = f\"trainging time : {timedelta_string(datetime.now() - start_time)}\"\n",
    "                example_count = f\"examples {n_example:8}\"\n",
    "                eval_loss = test_evaluate(test_set)\n",
    "                eval_losses.append((n_example,loss))\n",
    "                print (f'epoch {e:3} | {example_count} | loss:{loss_total:5.2f} | test loss:{eval_loss:5.2f} | {timestamp}')\n",
    "                loss_total = 0\n",
    "    return train_losses, eval_losses\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 13019\n"
     ]
    }
   ],
   "source": [
    "print(f\"total examples {len(sentence_pairs)}\")\n",
    "def train_test_split(total_examples, training_size = 1000,test_size = 100):\n",
    "    total_idx = [ i for i in range(len(total_examples))]\n",
    "    training_idx = [random.choice(total_idx) for _ in range(training_size)]\n",
    "    remaining_idx = list(set(total_idx) - set(training_idx))\n",
    "    test_idx = [random.choice(remaining_idx) for _ in range(test_size)]\n",
    "    assert set(test_idx).intersection(training_idx) == set([])\n",
    "    \n",
    "    training_examples = [total_examples[i] for i in training_idx]\n",
    "    test_examples = [total_examples[i] for i in test_idx]\n",
    "    \n",
    "    \n",
    "    training_set = [ pair2tensors(fra_lang, eng_lang, e , DEVICE) for e in training_examples]\n",
    "    test_set = [pair2tensors(fra_lang, eng_lang, e, DEVICE) for e in test_examples]\n",
    "    return training_set, test_set, training_examples, test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No attention: results\n",
    "\n",
    "    epoch   2 | examples    36000 | loss: 1.06 | test loss: 4.52 | trainging time : 0:00:09:44.56\n",
    "    \n",
    "With many of the random examples looking like:\n",
    "    \n",
    "    ['ils ne sont pas prepares a ca .', 'they re not prepared for this .']\n",
    "    ['they', 're', 'not', 'they', 're', 'not', 'they', 're']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_dim*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_dim * 2 , self.hidden_dim)\n",
    "        self.gru = nn.GRU(self.hidden_dim, self.hidden_dim)\n",
    "        self.out = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(x).view(1, 1, -1)) # (1, 1, h_dim)\n",
    "        \n",
    "        # (1,2 * h_dim) -> (1, max_l)\n",
    "        attn_weights = self.attn(torch.cat((hidden[0], embedded[0]), 1))\n",
    "        attn_weights = self.softmax(attn_weights) \n",
    "        \n",
    "        # (1,1,max_l) , (1,max_l,h_dim) - > (1, 1, h_dim)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1) # (1,1, 2 * h_dim)\n",
    "        output = self.relu(self.attn_combine(output).unsqueeze(0)) # (1,1, h_dim)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_dim, device=DEVICE)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_test_evaluate(test_set):\n",
    "    \n",
    "    for i, pair in enumerate(test_set):\n",
    "        input_tensor = pair[0]\n",
    "        target_tensor = pair[1]\n",
    "        loss_total = 0\n",
    "        with torch.no_grad():\n",
    "            loss = attn_eval_example(input_tensor, target_tensor, attn_enc, attn_dec, attn_optimizer, criterion)\n",
    "            loss_total += loss.item()/ target_tensor.size(0)\n",
    "        return loss_total\n",
    "    \n",
    "def attn_eval_example(input_tensor, target_tensor, attn_enc, attn_dec, attn_optimizer, criterion, teacher_forcing=0.5):\n",
    "    encoder_hidden = attn_enc.init_hidden()\n",
    "    attn_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, attn_enc.hidden_dim, device=DEVICE)\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = attn_enc(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0,0]\n",
    "        \n",
    "    dec_input = torch.tensor([[SOS_token]],device=DEVICE)\n",
    "    dec_hidden = encoder_hidden\n",
    "    \n",
    "    \n",
    "    \n",
    "    for di in range(target_tensor.size(0)):\n",
    "        dec_input, dec_hidden, dec_attention = attn_dec(dec_input, dec_hidden, encoder_outputs)\n",
    "        # for nll output = [batchsize, number of classes (words)] and target = correct class\n",
    "        loss += criterion(dec_input,target_tensor[di])\n",
    "        \n",
    "        if random.random()<teacher_forcing:\n",
    "            dec_input = target_tensor[di] #teacher forcing\n",
    "        else:\n",
    "            topv, topi = dec_input.topk(1)\n",
    "            dec_input = topi.squeeze().detach()\n",
    "            if dec_input.item() == EOS_token:\n",
    "                break\n",
    "    return loss\n",
    "\n",
    "def attn_train_step(input_tensor, target_tensor, attn_enc, attn_dec, attn_optimizer, criterion):\n",
    "    loss = attn_eval_example(input_tensor, target_tensor, attn_enc, attn_dec, attn_optimizer, criterion, teacher_forcing=True)\n",
    "    loss.backward()\n",
    "    attn_optimizer.step()\n",
    "    return loss.item()/ target_tensor.size(0)\n",
    "\n",
    "\n",
    "\n",
    "def attn_train(training_set, test_set, epochs, print_every):\n",
    "    set_size = len(training_set)\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for e in range(epochs):\n",
    "        for i, pair in enumerate(training_set):\n",
    "            n_example = ((e)*set_size + (i+1))\n",
    "            input_tensor = pair[0]\n",
    "            target_tensor = pair[1]\n",
    "            loss_total =0\n",
    "            loss = attn_train_step(input_tensor, target_tensor, attn_enc, attn_dec, attn_optimizer, criterion)\n",
    "            train_losses.append((n_example,loss))\n",
    "            loss_total += loss\n",
    "\n",
    "            if ((e)*set_size + (i+1))%print_every ==0:\n",
    "                timestamp = f\"trainging time : {timedelta_string(datetime.now() - start_time)}\"\n",
    "                example_count = f\"examples {n_example:8}\"\n",
    "                eval_loss = attn_test_evaluate(test_set)\n",
    "                eval_losses.append((n_example,eval_loss))\n",
    "                print (f'epoch {e:3} | {example_count} | loss:{loss_total:5.2f} | test loss:{eval_loss:5.2f} | {timestamp}')\n",
    "                loss_total = 0\n",
    "    return train_losses, eval_losses\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_random_infer(dset):\n",
    "    dummy_pair = random.choice(dset)\n",
    "    dummy_in = sentence2tensor(fra_lang, dummy_pair[0], DEVICE)\n",
    "    dummy_out = sentence2tensor(eng_lang, dummy_pair[1], DEVICE)\n",
    "    enc_h0 = attn_enc.init_hidden()\n",
    "    h = enc_h0\n",
    "    \n",
    "    enc_outputs = torch.zeros(MAX_LENGTH, attn_enc.hidden_dim, device=DEVICE)\n",
    "    for i in range(dummy_in.size(0)):\n",
    "        o, h = attn_enc(dummy_in[i], h)\n",
    "        enc_outputs[i] = o[0,0]\n",
    "    enc_h = h\n",
    "\n",
    "    outs = []\n",
    "    hidden = enc_h\n",
    "    output = torch.tensor([[SOS_token]], device=DEVICE)\n",
    "    for i in range(dummy_out.size(0)*2):\n",
    "        output, hidden, attention_weights = attn_dec(output, hidden, enc_outputs)\n",
    "\n",
    "        top_value, top_index = output.topk(1)  \n",
    "        output = top_index.squeeze().detach()\n",
    "        outs.append(output)\n",
    "        if output.item()==EOS_token:\n",
    "            break\n",
    "\n",
    "    print(f\"x : {dummy_pair[0]}\")\n",
    "    print(f\"y : {dummy_pair[1]}\")\n",
    "    print(f\"ŷ : {' '.join([eng_lang.index2word[o.item()] for o in outs])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set, training_examples, test_examples = train_test_split(sentence_pairs, 13000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderRNN(fra_lang.n_words).to(DEVICE)\n",
    "dec = DecoderRNN(eng_lang.n_words).to(DEVICE)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(itertools.chain(enc.parameters(),dec.parameters()),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : je suis tres reconnaissant pour votre aide .\n",
      "y : i m very grateful for your help .\n",
      "ŷ : i m not i m not i m not\n"
     ]
    }
   ],
   "source": [
    "random_infer(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = train(training_set, test_set, 3, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tu es connu .\n",
      "y : you re famous .\n",
      "ŷ : you re just going to\n"
     ]
    }
   ],
   "source": [
    "random_infer(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : je suis sur que ca changera bientot .\n",
      "y : i m sure that ll change soon .\n",
      "ŷ : i m sick of the moment i m sick\n"
     ]
    }
   ],
   "source": [
    "random_infer(test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rnn with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_dec = AttnDecoderRNN(hidden_dim=256, output_dim=eng_lang.n_words).to(DEVICE)\n",
    "attn_enc = EncoderRNN(fra_lang.n_words, hidden_dim=256).to(DEVICE)\n",
    "attn_optimizer = optim.SGD(itertools.chain(attn_enc.parameters(),attn_dec.parameters()),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : je n ai pas faim non plus .\n",
      "y : i m not hungry either .\n",
      "ŷ : flexible flexible documents bragging bragging bragging mop freak fat simple for behind armed japan\n"
     ]
    }
   ],
   "source": [
    "attn_random_infer(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_train_losses, attn_eval_losses = attn_train(training_set, test_set, 3, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : vous m attirez beaucoup .\n",
      "y : i m very drawn to you .\n",
      "ŷ : i m of the the . EOS\n"
     ]
    }
   ],
   "source": [
    "attn_random_infer(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : c est vraiment une fille adorable .\n",
      "y : she is indeed a lovely girl .\n",
      "ŷ : i m not afraid of the moment you\n"
     ]
    }
   ],
   "source": [
    "random_infer(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
